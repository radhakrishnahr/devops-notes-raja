AZ-900:
======

virtual machines :
------------------

> vm can be created under any RG and RG can be a part of Subscription.
> If we create vm, few other azure resources can be generated : vm, vnet, subnet, public IP, OsDisk, Network Interface, Network Security Group
> We can resize vm
> We can connect windows server using RDP (SSH, bastion)
> We can install (Web server) any features from server manager > Add Roles and features
> VM > DISKS > we can see os level disk which is managed disk(C:) for high available [ there is also temp disk(D:) is available which is not managable]
> When we deploy a vm, azure allocates public ip and private ip. 
> Using public ip (is another azure resource) we use rdp to connect with remote windows vm.
> Using private ip we can internally communicate within vnet.
> By default azure allocates static public ip by default. static public ip will not be change when we deallocating and reallocating the vm.
> public ip is dynamic in nature. If deallocate and reallocate vm, dynamic public ip will change.


Sizes of vm's :

1. General purpose [ ideal for testing and devleopment ] : B, Dsv3, DC, DCv2...etc
2. Compute optimized [ good for medium traffic web servers ] : F, Fs, Fsv2, FX
3. Memory optimized [ great for relatinal database servers ] : Esv2, Ev3, DVv2, M ...etc
4. Storage optimized [ Ideal for bigdata, sql,nosql databases ] : Lsv2,Lsv3, Lasv3
5. GPU [Specialized virtual machines targeted for heavy graphic rendering and video editing] : NC, NCv2, NCv3, NCasT4_v3...etc
6. Hign performance compute [Our fastest and most powerful CPU virtual machines with optional high-throughput network interfaces (RDMA).] : HB, HBv2, HBv3, HC

Windows / Linux Virtual Machines Pricing :

-> windows vm pricing depends on type of OS/software and region.
-> If we have any windows liecence, based on that liecence we'll get instant discount (Show Azure Hybrid Benefit pricing) on windows vm.
-> When we deploy an azure vm, based on its OS and region azzure will charge only for the vm only. Pricing for the other resources such as disk, vnet ..etc will be charged separately.

Why do we choose Region ?

> Region is geographical location of azure datacenter.
> In side a datacenter, we can have many racks of physical servers.
> Some services are available in region level and some are available in global level.
> based on azure service availability in the region, cost, distance to the users we need to choose region.

> Resource Group : logical entity to group of azure resources. Each resource is must be part of RG. A resource can't be part of multiple RG's or multiple subscriptions.
> Azure Marketplace for virtual machines : We can deploy required application from azure marketplace through the vm.
> Availability sets : It is a logical grouping of vm's. It helps to improve the entire availability of your application.
	> When physical server in datacenter is downdue to any fault / under maintenence, In such case, availability set helps to manage these issues through Fault domain and Update domain.
	> Update domain : Here Azure will apply updates to the physical infrastructure one update domain at a time.
	> Fault domain : Here the vm in the fault domain share a common power source and network switch.
	> There is no additional cost for availability set. Charges for underlying vm'see
	> Availability set is not reposible for to create vm's. It only manages availabilityof your machines.
	> Availability set is not replicate the data acroos the VM's.
> Availability zones : These are physical locations of datacenters in side the region. It is useful for the high availability of your application.
	> There is no cost of AZ's but there is a cost of data transfer per GB between AZ's. AZ will not replicate your application. It manages your app in AZ's. It is your responsibility to replicate your application in different AZ's.
> Azure dedicated host : It provides hardware isolation and no other vm's will be placed on the host. You can control maintenence events.
> Virtual machine scale set service : This service is resposible for to increase or decrease your resources automatically as per the demand. 

Azure Web App :
---------------

> If we want to host a web app on azure, we can use this service. This is PaaS.
> Azure only manages underlying infrastructure.
> This service can also scale up /down based on demand.
> This service has support for .NET, .NET Core, Java, Ruby, Node.js, PHP, Python.
> When we are creating Web app service, we need choose 'App Service Plan' for pricing purpose. It has Free F1, Shared D1, Basic B1 ,Standard S1, Premium V3 and Isolated V2 plans.

Azure Functions : 
----------------

> It is a Serverless service to host your function code in Azure.
> These is also an option to only pay based on your comsumption( no of invocations) of the function.
> There is support for c#, Java, JavaScript, PowerShell and Python etc
> It only charges for computation time of yout funtion in Azure's physical server.
> You no need to take care of any Infrastructure. 
> It has three plans ( Consumption(serverless), functions premium, app service plan )

Containers :
------------

> Isolate our application using container. It is light weighted and easy to export in any environment.
> We can run our application using container runtime such as docker.
> for to manage microserve based application we need kubernetes.

Azure container instance service :
----------------------------------

> This service is used to deploy our application using container.
> We can upload images from public or private container registry
> Azure provides their own service named azure container registry to host public/private docker images.

Azure kubernetes :
------------------

> We can deploy fully managed kubernetes service using Azure.
> It has different plans like Standard, Dev/Test, ...

Azure Virtual Desktop :
-----------------------

> To deploy a virtual desktop. we need any liecence key and it prices for remotely connecting to the virtual desktop.
> To set up virtual desktop, we need to create vnet and host pool.
> From azure active directory, we need to assign liecence to the user.
> From your host pool you need to assign virtual desktop to the user.

Azure virtual network (vnet) :
------------------------------

> when we define vnet, we have to specify ip address range (10.0.0.0/16).
> we can define subnets with proper IP adderess range (10.0.1.0/24).
> subnet ip range would be sub set of ip address range of vnet.
> when vm is deployed, a private ip is assigned based on ip range of subnet.
> azure vnet is equivalent to on-premesis network. and also it is isolated azure network.
> out bound traffic to the internet is allowed by default to the vnet.
> *** There is no need to deploy any azure resource with in the same region of RG.
> within the vnet, two subnets will communicate each other using their private ip's.

Network Security Groups :
-------------------------

> When we create a vm, it first creates NSG with default firewall rules and it gets attached to the Network Interface and the VM.
> NSG is acts like basic firewall to allows only valid traffic to the VM from the Intetrnet.
> It is uses to filter network traffic to/from azure resources with in VNET.
> We can assiciate NSG with either Network Interface or a subnet.
> The NSG contains rules that are used to allow or deny  inbound and outbound traffic.
> The rules can also be applied to all VM's inside the network.
> Default Inbound rules are AllowVnetInBound (priority=65000), AllowAzureLoadBalanceInBound (65001), DenyAllInBound (65500)
> Default Outbound rules are AllowVnetOutBound (65000), AllInternetOutBound (65001), DenyAllOutBound (65500)

Application Security Group :
----------------------------

> We can define one rule that allows Inbound traffic from 10.0.1.4 to 10.0.0.4.
> But here there is a dependency on the IP addess.
> Instead you canmake newvm part of an Application Security Group -  Let's say app-asg
> And then define the rule in the NSG to allow traffic ffrom app-asg to 10.0.0.4.

Overview of VPN connections to thr Azure :
------------------------------------------

> To connect vm located with in vnet from on-preses private network, By establishing point to site VPN we can communicate using private IP of Individual machine. for this we need to create azure virtual network gateway.
> Another way is to use site to site VPN to communicate machines from on-premises network to azure vnet. It also requires azure virtual netwr=ork gateway and Local network gateway.

Azure Express Route :
---------------------

> Allows you to connect your on-premises networks to Microsoft cloud over the private connection. Here the connection is established with the help of a connectivity provider
> The ExpressRoute connection does not go over the public Internet.
> Your connections are more reliable, faster and you get less latency.
> You get two connections for each ExpressRoute circuit for redundancy,


Azure Load Balancer :
---------------------

> The Load Balancer is used to distribute incoming traffic and distribute to the backend Azure VMs.
> There are different SKU's ( Pricing models ) for the LB- Basic and Standard.
> Basic LB - Nocharge -  But there is no SLA ( Service Level Agreement ). and there are other features like no built-in high availability.
> Standard LB has an hourly charge. But you get different features like high availability via the use of Availability zones.
> Public IP address - if it is a public load balancer.
> Configure backed pool - need to group backend VM's as a pool.
> Need to configure Health probe - This is used to monitor the balanced machines.
> Need to create Load Balancing rules ( NAT rules ) - These are used to direct the requests coming into the LB to the balanced VMs.
> Basic LB should be a part of scale set or availability set.

Azure DNS Zone:
---------------

> You could access the web application via the Public IP address or the DNS allocated by Azure.
> You can route the user traffic to your application via your own domain name.
> You can use the Azure DNS service when it comes to name resolution.
> You can also use the Azure DNS system to manage the DNS records.

Azure virtual network peering :
-------------------------------

> An Azure vnet is an isolated network on the cloud.
> By defaultthe azure vm's can't communicate acroos azure vnet's.
> for this you have to create a azure vnet peering connection.
> We can peer from two different subscriptions and also we can peer from two different accounts.

Introduction to Azure Storage :
===============================

> Types of Azure storage accounts : 
		> Azure storage account - blob storage : 
		----------------------------------------
			> Is is an object storage best used to store unstructured data like videos, pics, audio files using Azure storage accounts.
			> Azure blob storage can grow automatically based on demand.
			> It is also good for storing backups.
		> Azure Storage account - file shares :
		---------------------------------------
			> Ex : Let us consider a company wants to maintain their each employee data. Then this serivce best suitable to fullfill this scenario.
		> Azure Storage account - table storage :
		-----------------------------------------
			> This is great when you want to store non-relational structured data. This is when you data conforms to a schemaless design.
		> Azure storage account - queue storage :
		-----------------------------------------
			> This is simple messaging based service.
> Storage account name should be unique.
> After creating storage account, we can see all types of storage accounts (containers, file shares, queues, tables) left side of storage account dashboard. 

BLOB service :
--------------

> create a storage account > click on container > create new container > upload files from local system / from any resource.
> It is object based storage system as it treats files as objects.
> We will get URL for each object. Using URL we can access the object through browser.
> To read data by anyone, we need to modify public access level to anonymous read access for blobs only. ( under container > beside upload > click on change access level )
> we can upload, modify or delete objects.

Azure Storage Accounts - Access tiers :
---------------------------------------

> Blob storage pricing :
	> Pricing is depends on  * Volume of data stored per month.
							 * Quantity and types of operations performed, along with any transfer costs.
							 * Data redundancy option selected.
							 * Based on file structure (flat namespace).
							 * data storage prices pay-as-you-go have different options like Premium, Hot, Cool, Archive.
				Premium			Hot				Cool 			Archive
				-------			---				----			-------
1st 50TB/month		$0.15.GB		$0.0184/GB		$0.01/GB		$0.00099/GB
Next 450T/m		$0.15.GB		$0.0177/GB		$0.01/GB		$0.00099/GB
Over 500T/m		$0.15.GB		$0.0170/GB		$0.01/GB		$0.00099/GB

> There is a cost for storing objects.
> There is a cost for accessing objects.
> Companies might store millions of objects in a storage account.
> Use case : Initial there could be some objects that are accessed quite frequently. Then after some time, may be a week or two, those objects are accessed less frequently.
	can company save on costs when it comes to less frequentlyaccessed objects. 
> An object can be set to a particular tier.
> Hot Access tier : This is optimized for objects accessed more frequently. ( here you have storage costs and lower access costs )
> Cool Access tier : This is optimized for objects accesed or modified less frequently. ( here you have less storage costs and high access costs )
		( Here data need to be stored for at least 30 days )
> Archive Acces tier : Good for longterm backups. ( here you have lower storage costs and very higher access costs ).
		( Here the data need to be stored for at least 180 days )
> We can set the hot and cool access tier at the storage account level.
> We can set the hot, cool and archive access tier at the blob level.
> By default blob storage will be in hot access tier.
> From container configuration, we can change access tier hot or cool.
> from each object also we can change tier to any.
> If the object is in archive access tier, there is no option to download the object.
> for cool access tier, we are to download and access the object.
> If we want to access archive object, we need to rehydrate the object to cool or hot with rehydrate priority. This will be standard or high.
> For standard rehydrate priority, archive object will take take several hours to complete conversion from archive to hot/cool.
> It will charge for some price for conversion.

Azure storage accounts -  Data redundancy :
-------------------------------------------

> When we creating storage account, we can see option to set the redundancy. want
> We have different types of redundancies : Locally-redundant storage(LRS), Geo-redundant storage (GRS), Zone-redundant storage (ZRS), Geo-Zone-redundant storage (GZRS)
> Locally-redundant storage(LRS) : 3 copies of your data are made in one data center to prevent any sudden server failures in the data center.
> Zone-redundant storage (ZRS) : This helps to protect againest data center level failures. here data replicated sync'ly across three azure availability
> Geo-redundant storage (GRS) : For higher data redundancy, 3 copies of data is replicated in current datacenter using LRS and also in another region using LRS.
> Read access Geo-redundant storage : 
> Geo-Zone-redundant storage (GZRS) : For higher data redundancy, 3 copies of data replicated over the 3 availabilityzones of two different regions.
> Read only Geo-Zone-redundant storage :

> Azure file shares :
---------------------
> With in storage account, we can see option to create file shares.
> once file shares is created we can upload file with in the file share.
> For each file share we can connect using connect option and copy the powershell script from your local machine.
> Then it will create a z: directory under that we can see our file and also we can add some other files in that z: directory.
> To remove that z: directory, we need to execute powershell command : net use z:\ /delete

> Azure File Sync service :
---------------------------
> Using this service we can use on-premesis windows server which stores azure cloud file shares in the cache memory to quick access of the files to the users.
> Here one of the steps is to download and install the azure file sync agent on the wondows server.

> Azure Queue storage :
-----------------------
> It is a simple messaging service. we can keep messages in the queue.
> Storage account > queues > create > Add messages and dequeue messages

> Azure table storage : 
-----------------------

> used to store non-relational structured data. (nosql database)
> storage account > tables > create table
> to add table, storage account > storage browser > tables > click on the table > add entity [ we can add property name, type and value ]
> Inside the table, first two properties are PartitionKey and RowKey.
> PartitionKey and RowKey are helps to search for the particular property in the table.

Azure Premium storage accounts :
--------------------------------
> Premium block blobs :
-----------------------
	> This is used when you need high performance when it comes to storage and access to data.
	> Here the data in the background is stored on solid-state drives. These are optimized for low latency.
	> Here the file transfer is alos much faster.
	> Workloads : Straming, Machine learning.
	> You have higher storage costs but lower transaction costs.
	> Data redundancy may be LRS or ZRS.
	> There is no option to set access tiers.
> Premium File shares :
	> Here again you get high performance and low latency
	> Backend by solid-state drives for storage.
	> Data redundancy may be LRS or ZRS.
> when we are creating storage account, we need to choose Premium option, there we can choose Premium account type ( Bolck blobs, File shares and Page blobs )
> Page blobs are normally we store virtual hard disk files that are linked to the VMs. Page blobs are best for random read write operations.
> We can see options like containers, queues, tables, File shares under the premium storage account.

Azure Storage explorer :
------------------------

> It is software tool ( SDK ) need to be install in our local machine to manage azure storage accounts under the local environment.

Data migration to Azure :
-------------------------

> As per the azure documentation, we have many solutions to migrate on-premise server to the azure.
> Using Azure Data Box, we can migrate tera bytes of data in or out to the azure account.

AzCopy tool :
-------------

> It is a command line utility to copy blobs or files to or from a storage account.
> download the utility > inside the path > execute azcopy command
> azcopy make "https://appstore355456.blob.core.windows.net/tmp?<-shared-access-signature->" --> to create a container
> azcopy copy service.yml "https://appstore355456.blob.core.windows.net/tmp/service.yml?<-shared-access-signature->" --> to upload a file

Virtual Network Service Endpoints :
-----------------------------------

> This provide secure and direct connectivity to azure services over the azure backbone network.
> step 1 : vnet > service endpoints > Add > Microsoft.Storage >  provide details and add
  step 2 : Storage account ( same region ) > Networking > Firewalls and virtual networks > enabled from vnet and ip addresses and also add your client IP address ( Firewall ) > save.


  Introduction to the Azure data base services :
==============================================

Azure SQL Database service :
============================

> PaaS
> The underlined compute infrastructure and the backups are managed by Azure.
> We'll built-in high availability.
> SQL Database > sub, rg, name, select a server [ create ] > configure [ service tier ( Basic, Premium, ... etc ) ] > Networking > Security > Tags > Review and create
> We can see two resources : sql database and sql server
> Open Microsoft SQL Server Management Studio tool in your local machine as administrator > provide credentials > and connect 
> From azure portal, open your sql database > query editor > provide credentials and connect.
> Add data from the tool, right click on our data base name and choose new query > we can execute sql commands.
> We can delete our table by expanding our data base directory and right click on the table located inside the tables directory and delete the table.
> Add data from the portal, After login to our database > we can see our query window which uses to execute sql querries
> We can disconnect from the tool or azure portal.
> query to create a table :
CREATE TABLE Course
(
   CourseID int,
   CourseName varchar(1000),
   Rating numeric(2,1)
)
> query to insert data in the table :
INSERT INTO Course(CourseID,CourseName,Rating) VALUES(1,'AZ-204 Developing Azure solutions',4.5)
 
INSERT INTO Course(CourseID,CourseName,Rating) VALUES(2,'AZ-303 Architecting Azure solutions',4.6)
 
INSERT INTO Course(CourseID,CourseName,Rating) VALUES(3,'DP-203 Azure Data Engineer',4.7)
> Query to see the table
SELECT * FROM Course

Azure Database for MySQL :
--------------------------

> Open Azure Database for MySQL > Flexible server [ create ] > sub, rg, name, server name, region, MySQL version, workload type ( small , buisiness critical, dev ) > compute + storage ( configure --> to set size, compute, pricing ) > provide username and password > networking > security > tags > review and create
> After creating this, we can see only one resource.
> to connect to the server, we can download and install MySQL Workbench tool (free tool) > open > new MySQL > provide server information and credentials > ok
> Create tables by executing following sql queries :
create database appdb;

use appdb;

CREATE TABLE Customer(
	Customerid VARCHAR(100),
	CustomerName VARCHAR(100)
);

INSERT INTO Customer(Customerid,CustomerName) VALUES('C1','UserA');
INSERT INTO Customer(Customerid,CustomerName) VALUES('C2','UserB');
INSERT INTO Customer(Customerid,CustomerName) VALUES('C3','UserC');

SELECT * from Customer;

> we can delete all resources.

Azure Database for PostgreSQL :
-------------------------------
> Open Azure Database for PostgreSQL > Flexible server [ create ] > sub, rg, name, server name, region, MySQL version, workload type ( small , buisiness critical, dev ) > compute + storage ( configure --> to set size, compute, pricing ) > provide username and password > networking > security > tags > review and create
> To use this service, we need to use Azure Data Studio tool > Open > install PostgresSQL > connections > new connection > provide server information and credentials > connect
> New query > execute queries
create database appdb;

CREATE TABLE Customer(
	Customerid VARCHAR(100),
	CustomerName VARCHAR(100)
);

INSERT INTO Customer(Customerid,CustomerName) VALUES('C1','UserA');
INSERT INTO Customer(Customerid,CustomerName) VALUES('C2','UserB');
INSERT INTO Customer(Customerid,CustomerName) VALUES('C3','UserC');

SELECT * from Customer;

> We can delete our database.

Enterprise Data Warehouse Architecture :
----------------------------------------

> e-commerce example : To manage the lots of unstructured data from so many sources Ingest services such as Azure Synapse Pipelines and Azure Data Factory takes data
	from the different sources and stores the data using Azure Data Lake Gen2 storage accounts and prepare and train the data using Azure synapse apache spark and Azure Databricks we can host the data in Azure synapse dedicated SQL Pool.

> creating azure data lake through storage account : Create storage account ( enable data lake in advanced tab ) -> Using monitor service > Activity log > download csv -> upload this file in a contianer
> creating synopse workspace : open azure synapse analytics > create > ..workspace name ( unique ), storage account name, file system name > security ( provide creds to the sql server ) > networking > tags > review and create
> go to the synapse workspace > sql pools > New > additional settings > tags > review and creat.
> connect to the dedicated sql pool using sql server management studio tool > we can see our sql pool by expanding databases directory.
> open synapse workspace > open synapse studio from azure portal > click on Data > SQL database > we can see our sqlpool > Tables 
																 > Integrate > create pipeline
																			 > copy data tool > next > select azure datalake storga gen2 > storage account name > create
																							  > next > provide destination as your sql server > next > finish
> After data warehousing lab clean up your resources.

Azure Cosmos DB :
-----------------

> Fully managed NoSQL DB (serverless)
> You get single digit milli second reposponse times.
> scales automatically based on demand.
> Based api of different db's, we can migrate accordingly using azure cosmos db.  ex : sql api, MongoDB, Gremlin, Cassandra, Table.
> cosmos db > for NoSQL > ... > review and create
> cosmos db > database account > database > container > items > provide partition key and create.
> click on db > items > add items using json format > save 
> we can perform crud operations.
{
"customerid":"C1",
"customername":"UserA",
"customercity":"Chicago"
}

{
"customerid":"C2",
"customername":"UserB",
"customercity":"Chicago"
}

{
"customerid":"C3",
"customername":"UserC",
"customercity":"New York"
}

Azure SQL Database vs Azure Cosmos DB :
---------------------------------------

> When you need to have relationaships between tables and when you want to have constraints like foreign key containts then we use Azure SQL Database service
> Cosomos DB is fully managed NoSQL DB. We can use flexible schemas and no need of joins between data structures

Azure DataBricks :
------------------

> Data Bricks > create workspace > ... 
> open workspace > launch workspace > sign in 
> create a cluster ( used to analyse the data )
> storage account should be in place for data lake.
> create notebook > python code > run
blob_account_name = "datalake100299"
accountkey="W2ucVHdKQn4RZwqBu+H9TKa0bnpYK00BINXOwnviJZXNzwHa9Df7R7TuJ09Vcmznpu9EYclJbEX6eO50pkpdYQ=="
wasbs_path = "wasbs://data@datalake100299.blob.core.windows.net"
fullname = "fs.azure.account.key." +blob_account_name+ ".blob.core.windows.net"
 
dbutils.fs.mount(
  source = wasbs_path,
  mount_point ="/mnt/data",
  extra_configs = {fullname : accountkey})
 
ds = spark.read.csv("/mnt/data/Log.csv")
display(ds)

Azure Cloud Concepts :
======================

High Availability : 
-------------------

> App --> VM ( OS Disk and Data Disk )  [ service level agreement ] ( if failure )
> App --> VM VM VM ( Availability set or Availability zone )
> Storage Accounts --> zone-redundant storage or Geo-redundant storage

Scalibility :
-------------

> We have virtual machine scale set service. which uses to provision or deprovision our VMs based on the demand.
> We don't need to worry about underlined storage of storage account. It automatically scales based on demand.

Disaster recovery :
-------------------

> We can protect our data in case of any disasters by using availability set, availability zones.
> For storage accounts, we need to use Geo-redundant storage.
> cost analysis : quick switch over from primary to secondary region, additional cost based on cost benfit analysis based on what will be loss for the down time of the application versus having that duplicate infrastructure is running on the secondary region.

Elasticity :
------------

> The ability to grow or shrink resources automatically as part of cloud platform
> Ex : for vm, we can resize the vm

Fault tolerance :
-----------------

> Suppose any fault ( error ) occurs for a high available application, it breaks our application. At this time fault tolerance is the ability to quickly revert back of your application.
> If fault occurs in a data center level, then your application will run from another availability zone.
> For Storage accounts, we have zone/geo redundant storage options.

Cloud Service Model :
---------------------

> IaaS : Ex : VM -> infra provided by cloud and managed by user. ( Admins )
> PaaS : Ex : Azure SQL Database -> underlined infrastructure and os is managed by azure and software can be managed by user. ( Developers )
> SaaS : Ex : Microsoft Office 365 -> Underlined infrastructure and the software is managed by azure. End user use the application ( End users )

Cloud Model types :
-------------------

> Public Cloud : Cloud can be used be any one.
> Private Cloud : Cloud can you used by particular organization.
> Hybrid Cloud : Based on requirement we can use public cloud and private cloud.

Economies of scale :
--------------------

> Basics : This is the ability to carry out taks more efficiently or at a lower-cost per unit when operating at a large scale.
> discounts : When the demand increases, cloud provides can then get hardware at discount prices.
> Benfit : This becomes a benfit to the customer wherein the discounts can be passed to the customer.
> service cost : If the number of customers increase the chances of services costs can go down.
> Captital Expenditure ( CapEx ) : This is when you pay money upfront [ one time investment ]( buying building, servers, storage, software liecences )
> Operational Expenditure ( OpEx ) : Ongoing money spent on services ( Human Resources, Maintenance, software support, data center costs - cooling )

Shared Responsibility Model :
-----------------------------

> Division of responsibility :
		> On-prem : Everything can be resposible for you.
		> IaaS : Physical hosts, network, data center has responsibility of cloud. Remaining things has responsibility of user.
		> PaaS : In addition with IaaS, Azure has shared responsibility in Identity and directory infrastructure, applications, network controls with user.
		> SaaS : User is reponsible for Information and data, devices, accounts and identities. Azure had shared responsibility with Identity and directory infrastructure.



									












